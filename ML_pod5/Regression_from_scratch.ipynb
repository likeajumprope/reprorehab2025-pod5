{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Regression from scratch\"\n",
        "---"
      ],
      "id": "4155ba0c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Components of a machine learning algorithm (linear regression)\n",
        "\n",
        "\n",
        "| Symbol Type | Example | Typical Shape | Description |\n",
        "|--------------|----------|----------------|--------------|\n",
        "| **Scalar** | $a, b, x_i, y, \\eta$ | $1 \\times 1$ | Single numeric value (e.g., a feature value, bias, or loss). |\n",
        "| **Vector** | $\\mathbf{x}, \\mathbf{w}, \\boldsymbol{\\theta}$ | $p \\times 1$ | Column vector containing multiple values (e.g., features or parameters). |\n",
        "| **Matrix** | $\\mathbf{X}, \\mathbf{W}, \\mathbf{A}$ | $n \\times p$ | 2-D array (rows = samples, columns = features). |\n",
        "| **Dot product** | $\\mathbf{w}^T \\mathbf{x}$ | scalar | Inner product between two vectors. |\n",
        "| **Outer product** | $\\mathbf{x}\\mathbf{w}^T$ | $p \\times p$ | Creates a matrix from two vectors. |\n",
        "| **Inverse** | $\\mathbf{A}^{-1}$ | $p \\times p$ | Matrix that “undoes” multiplication by $\\mathbf{A}$, if it exists. |\n",
        "| **Hat notation** | $\\hat{y}$ | scalar or vector | Estimated or predicted value (e.g., $\\hat{y}$ = model prediction). |\n",
        "| **Bar notation** | $\\bar{x}$ | scalar or vector | Mean or average value (e.g., $\\bar{x}$ = sample mean). |\n",
        "\n",
        "\n",
        "## 1. The model\n",
        "\n",
        "The mathematical structure or function family that maps inputs to outputs (supervised learning). The model defines what forms of relationships between input and output can be learned.\n",
        "\n",
        "### For linear regression:\n",
        "\n",
        "#### 1. Scalar form\n",
        "Each observation \\(i\\) has its own equation:\n",
        "$$\n",
        "\\hat{y}_i = w_0 + w_1 x_{i1} + w_2 x_{i2} + \\dots + w_p x_{ip} + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "#### 2. Vector (standard math) form\n",
        "Compact form for a single observation using vectors:\n",
        "$$\n",
        "\\hat{y}_i = \\mathbf{w}^T \\mathbf{x}_i + b + \\varepsilon_i\n",
        "$$\n",
        "\n",
        "\n",
        "#### 3. Matrix form\n",
        "All \\(n\\) observations combined (X stacks row vectors):\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w} + \\mathbf{b} + \\boldsymbol{\\varepsilon}\n",
        "$$\n",
        "or (if \\(b\\) is absorbed as an intercept column of ones in \\(\\mathbf{X}\\)):\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w} + \\boldsymbol{\\varepsilon}\n",
        "$$\n",
        "\n",
        "\n",
        "## 2. Input Data\n",
        "\n",
        "- Examples: images, text, sensor data, neuroimaging features, etc.\n",
        "- Often represented as a matrix X of shape $(n_{samples}, n_{features})$.\n",
        "- Data needs to be cleaned, normalized, encoded, and sometimes split into train/test sets.\n",
        "\n",
        "\n",
        "### The target variable Y (what should be predicted)\n",
        "$$\n",
        "Y = \n",
        "\\begin{bmatrix}\n",
        "y_1 \\\\\n",
        "y_2 \\\\\n",
        "y_3 \n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "### The input data (what predicts)\n",
        "$$\n",
        "X = \n",
        "\\begin{bmatrix}\n",
        "1 & \\text{Age}_1 & \\text{Sex}_1 \\\\\n",
        "1 & \\text{Age}_2 & \\text{Sex}_2 \\\\\n",
        "1 & \\text{Age}_3 & \\text{Sex}_3\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "\n",
        "### 3. Parameters (Weights / Coefficients)\n",
        "\n",
        "The tunable variables that define a specific instance of the model.\n",
        "\n",
        "Examples:\n",
        "\n",
        "- \tw, b in linear regression\n",
        "- \tConnection weights in a neural network\n",
        "- \tDuring learning, these parameters are adjusted to best fit the data\n",
        "    \n",
        "$$\n",
        "w = \n",
        "\\begin{bmatrix}\n",
        "w_1 \\\\\n",
        "w_2 \\\\\n",
        "w_3 \n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "## Detour: Matrix multiplication\n",
        "\n",
        "Matrix multiplication is one of the most common operations in linear algebra.\n",
        "\n",
        "\n",
        "When we multiply two matrices, the **number of columns in the first** must match the **number of rows in the second**.  \n",
        "If $\\mathbf{A}$ is of shape $m \\times n$ and $\\mathbf{B}$ is of shape $n \\times p$,  \n",
        "then the result $\\mathbf{C} = \\mathbf{A}\\mathbf{B}$ will have shape $m \\times p$.\n",
        "\n",
        "Each element of the result is the **dot product** of a row from $\\mathbf{A}$ and a column from $\\mathbf{B}$:\n",
        "\n",
        "$$\n",
        "c_{ij} = \\sum_{k=1}^{n} a_{ik} b_{kj}\n",
        "$$\n",
        "\n",
        "As an example, here is the multiplication of a 2 x 3 by a 3 x 2 matrix, resulting in a 2 x 2 matrix: \n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w} + \\mathbf{b} + \\boldsymbol{\\varepsilon} =\n",
        "$$\n",
        "\n",
        "$$\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "a_{11} & a_{12} & a_{13} \\\\\n",
        "a_{21} & a_{22} & a_{23}\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "b_{11} & b_{12} \\\\\n",
        "b_{21} & b_{22} \\\\\n",
        "b_{31} & b_{32}\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "a_{11}b_{11} + a_{12}b_{21} + a_{13}b_{31} & a_{11}b_{12} + a_{12}b_{22} + a_{13}b_{32} \\\\\n",
        "a_{21}b_{11} + a_{22}b_{21} + a_{23}b_{31} & a_{21}b_{12} + a_{22}b_{22} + a_{23}b_{32}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Exercise:\n",
        "\n",
        "### Exercise: Linear Regression Prediction\n",
        "\n",
        "A linear regression model estimates the relationship between predictors (features) and a target variable.  \n",
        "Given an **input matrix** $\\mathbf{X}$ and a **weight vector** $\\mathbf{w}$, the model predicts target values $\\hat{\\mathbf{y}}$ according to:\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w}\n",
        "$$\n",
        "\n",
        "\n",
        "#### **Task**\n",
        "\n",
        "You are given the following data X, that the following weights w were fitted to:\n",
        "\n",
        "$$\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "1 & 4 \\\\\n",
        "1 & 6\n",
        "\\end{bmatrix},\n",
        "\\quad\n",
        "\\mathbf{w} =\n",
        "\\begin{bmatrix}\n",
        "0.5 \\\\\n",
        "1.2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "1. Compute the **predicted values** $\\hat{\\mathbf{y}}$ (by hand).\n",
        "\n",
        "2. Do the same using the [numpy package using the dot product](https://numpy.org/devdocs/reference/generated/numpy.dot.html):\n",
        "```\n",
        "import numpy as np\n",
        "X = np.array([[1,2],[1,4],[1,6]])\n",
        "w = np.array([[0.5],[1.2]])\n",
        "```\n",
        "\n",
        "::: {.callout-tip title=\"Solution\" collapse=\"true\"}\n",
        "**Goal:** Compute $\\hat{\\mathbf{y}} = \\mathbf{X}\\mathbf{w}$.\n",
        "\n",
        "**Given**\n",
        "$$\n",
        "\\mathbf{X} =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "1 & 4 \\\\\n",
        "1 & 6\n",
        "\\end{bmatrix},\n",
        "\\quad\n",
        "\\mathbf{w} =\n",
        "\\begin{bmatrix}\n",
        "0.5 \\\\\n",
        "1.2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Step-by-step**\n",
        "$$\n",
        "\\hat{\\mathbf{y}} =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "1 & 4 \\\\\n",
        "1 & 6\n",
        "\\end{bmatrix}\n",
        "\\begin{bmatrix}\n",
        "0.5 \\\\\n",
        "1.2\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "1\\cdot0.5 + 2\\cdot1.2 \\\\\n",
        "1\\cdot0.5 + 4\\cdot1.2 \\\\\n",
        "1\\cdot0.5 + 6\\cdot1.2\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "2.9 \\\\\n",
        "5.3 \\\\\n",
        "7.7\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Result**\n",
        "$$\n",
        "\\hat{\\mathbf{y}} =\n",
        "\\begin{bmatrix}\n",
        "2.9 \\\\\n",
        "5.3 \\\\\n",
        "7.7\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "** Using NumPy check**\n",
        "```python\n",
        "import numpy as np\n",
        "X = np.array([[1,2],[1,4],[1,6]])\n",
        "w = np.array([[0.5],[1.2]])\n",
        "#y_hat = X @ w\n",
        "np.dot(X,w)\n",
        "y_hat\n",
        "```\n",
        ":::\n",
        "\n",
        "### 4. Objective or Loss Function\n",
        "\n",
        "A quantitative measure of how well the model performs.\n",
        "\n",
        "- \tIt defines the goal of learning.\n",
        "- Examples:\n",
        "\t- Mean Squared Error (MSE) for regression\n",
        "\t- Cross-Entropy Loss for classification\n",
        "\t- Negative log-likelihood for probabilistic models\n",
        "\t\n",
        "Aim: The algorithm tries to minimize (or maximize) this loss function.\n",
        "\n",
        "\n",
        "Example: mean squared loss\n",
        "$$\n",
        "L = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
        "$$\n",
        "\n",
        "$L$ — total loss (the value we minimize)\n",
        "\n",
        "$n$ — number of samples\n",
        "\n",
        "$y_i$ — true (observed) value for sample i\n",
        "\n",
        "$\\hat{y}_i$ — predicted value for sample i\n",
        "\n",
        "The squared difference $(\\hat{y}_i - y_i)^2$ measures the error for each prediction.\n",
        "Taking the mean makes the loss independent of sample size.\n",
        "\n",
        "#### **Task**\n",
        "\n",
        "You are given a target vector $y$, in addition to the previous vector $\\hat{y}$:\n",
        "\n",
        "$$\n",
        "\\mathbf{y} =\n",
        "\\begin{bmatrix}\n",
        "3.0 \\\\\n",
        "5.0 \\\\\n",
        "8.0\n",
        "\\end{bmatrix},\n",
        "\\qquad\n",
        "\\hat{\\mathbf{y}} =\n",
        "\\begin{bmatrix}\n",
        "2.9 \\\\\n",
        "5.3 \\\\\n",
        "7.7\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "1. Calculate the mean square loss between the predicted changes from the previous task and the target vector y by hand.\n",
        "\n",
        "2. Write a **function** in python to do it. The function should take $y$ and $\\hat{y}$ as input and return the mean squared loss:\n"
      ],
      "id": "93ed90dd"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "Loss = mean_quared_loss(y, y_hat)"
      ],
      "id": "8b145e4a",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}